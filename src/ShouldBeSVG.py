#!/usr/bin/env python3
# coding: utf-8
# SPDX-License-Identifier: Apache-2.0


# Copyright 2019 AntiCompositeNumber

# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at

#   http://www.apache.org/licenses/LICENSE-2.0

# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""Generates reports for highly-used images that should use vector graphics."""

import datetime
import argparse
import re
import json
import pywikibot
import logging
import utils
from collections import namedtuple
from pywikibot import pagegenerators

__version__ = "1.3"
logging.dictConfig(
    utils.logger_config("ShouldBeSVG", level="VERBOSE", filename="ShouldBeSVG.log")
)
logger = logging.getLogger("ShouldBeSVG")
UsageResult = namedtuple("UsageResult", ["gallery", "total", "skipped"])


def get_usage(cat, depth, total):
    """Get usage information for every file in the supplied category"""
    gen = pagegenerators.CategorizedPageGenerator(
        cat, recurse=depth, namespaces=6, total=total
    )

    # Generate a dictionary with diagrams that should be SVG.
    usage_counts = {}
    skipped = []

    for page in gen:
        # First, grab the mimetype of the file.
        # If that's not possible, the file is broken and should be skipped.
        try:
            mimetype = pywikibot.FilePage(page).latest_file_info.mime
        except (pywikibot.PageRelatedError, AttributeError):
            skipped.append(page.title())
            logger.info("Skipping", page)
        else:
            # The categories are a bit messy, so make sure the image isn't
            # already an SVG.
            if mimetype != "image/svg+xml":
                try:
                    usage = pywikibot.FilePage.globalusage(page)
                    usage_counts[page] = len(list(usage))
                except (pywikibot.NoUsername, pywikibot.PageRelatedError):
                    # Pywikibot complains if the bot doesn't have an account
                    # on a wiki where a file is used. If that happens,
                    # skip the file.
                    skipped.append(page.title())
                    logger.info("Skipping", page)

    # Sort from greatest to least
    usage_counts_sorted = sorted(
        usage_counts, key=usage_counts.__getitem__, reverse=True
    )

    # Count the global usage for the top 200 files
    i = 0
    j = 200
    sorted_pages = ""
    for page in usage_counts_sorted:
        if i < j:
            i += 1
            sorted_pages += f"{page.title()}|{i}. Used {usage_counts[page]} times.\n"

    logger.info("Scanning finished")
    return UsageResult(sorted_pages, len(usage_counts), skipped)


def construct_gallery(cat, usage_result, depth):
    """Take the output from get_usage() and turn it into a wikitext gallery"""
    date = datetime.date.today()
    cats = "'''[[:{cat.title()}]]''' ({cat.categoryinfo['files']} files) \n"
    page_cats = "{cat.aslink()}\n" "[[Category:Images that should use vector graphics]]"

    # Figure out which subcategories were scanned and turn those into a list
    if depth > 0:
        for subcat in cat.subcategories(recurse=depth - 1):
            cats += f"* [[:{subcat.title()}]] ({subcat.categoryinfo['files']} files) \n"

    # If any files were skipped, write an explanatory message and the files.
    skipped = usage_result.skipped
    if skipped != []:
        skipped_files = (
            "The following files were skipped due to errors "
            "during the generation of this report:\n"
        )
        for page in skipped:
            skipped_files += f"* [[:{page.title()}]]\n"
    else:
        skipped_files = "\n"

    # Now we construct the gallery itself. Everything is formatted by now,
    # it just needs to be slotted into the right spot.
    gallery = f"""\
Last update: {{{{ISODate|1={date}}}}}.

This report includes the following categories while counting only the usage \
of each file in the main namespace.

{cats}
Total number of scanned files: {usage_result.total}
<gallery showfilename=yes>
{usage_result.gallery}
</gallery>

This report was generated by AntiCompositeBot {__version__}. {usage_result.skipped}
{page_cats}"""
    return gallery


def save_page(target, gallery):
    """Saves the page to Commons, making sure to leave text above the line"""
    old_wikitext = target.text
    regex = re.compile(
        "(?<=<!-- Only text ABOVE this line " "will be preserved on updates -->\n).*",
        re.M | re.S,
    )
    new_wikitext = re.sub(regex, gallery, old_wikitext)

    utils.retry(
        utils.save_page,
        2,
        text=new_wikitext,
        page=target,
        summary=f"Updating gallery (Bot) (#ShouldBeSVG{__version__})",
        bot=False,
        minor=False,
    )


def handle_args():
    # Handle command line arguments. See ShouldBeSVG.py --help for details
    parser = argparse.ArgumentParser(
        description=("Generate global usage reports" "for vectorization categories.")
    )
    parser.add_argument("key")
    parser.add_argument(
        "--total", help="maximum number of files to scan", type=int, default=None
    )
    parser.add_argument(
        "--simulate",
        action="store_true",
        help="prints output to stdout instead of saving it",
    )
    parser.add_argument(
        "--run_override",
        action="store_true",
        help="force the bot to ignore the runpage",
    )
    parser.add_argument("--version", action="version", version=__version__)
    return parser.parse_args()


def find_report(args, times):
    if args.key == "auto":
        dt = datetime.datetime.utcnow()
        now = dt.strftime("%u%H")
        try:
            report = times[now]
        except KeyError:
            logger.error("Check your timing, there's no report to run this hour", now)
            raise
    else:
        report = args.key

    return report


def main():
    args = handle_args()

    site = pywikibot.Site("commons", "commons")
    utils.check_runpage(site, "ShouldBeSVG", args.run_override)

    logger.info("Starting up")

    # Download a dict relating keys to galleries, categories, and depth values.
    reports_page = pywikibot.Page(
        site, "User:AntiCompositeBot/ShouldBeSVG/reports.json"
    )
    reports = json.loads(reports_page.text)["reports"]
    times = json.loads(reports_page.text)["times"]

    key = find_report(args, times)
    cat = pywikibot.Category(site, reports[key]["category"])
    target = pywikibot.Page(site, reports[key]["gallery"])
    depth = reports[key]["depth"]
    total = args.total

    usage_result = get_usage(cat, depth, total)

    gallery = construct_gallery(cat, usage_result, depth)

    if args.simulate:
        logger.debug(gallery)
    else:
        save_page(target, gallery)

    logger.info("Finished")


if __name__ == "__main__":
    try:
        main()
    except Exception as err:
        logger.exception(err)
        raise err
