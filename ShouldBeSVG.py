#!/usr/bin/env python3
# coding: utf-8
# SPDX-License-Identifier: Apache-2.0


   # Copyright 2019 AntiCompositeNumber 

   # Licensed under the Apache License, Version 2.0 (the "License");
   # you may not use this file except in compliance with the License.
   # You may obtain a copy of the License at

       # http://www.apache.org/licenses/LICENSE-2.0

   # Unless required by applicable law or agreed to in writing, software
   # distributed under the License is distributed on an "AS IS" BASIS,
   # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
   # See the License for the specific language governing permissions and
   # limitations under the License.

version = 'ShouldBeSVG 0.5.1'

import pywikibot
from pywikibot import pagegenerators
import datetime
import argparse
import re

def getUsage(cat, depth, total):

    gen = pagegenerators.CategorizedPageGenerator(cat, recurse=depth,
                                                  namespaces=6,total=total)

    # Generate a dictionary with diagrams that should be SVG.
    usageCounts = {}
    skipped = ''

    for page in gen:
        # First, grab the mimetype of the file.
        # If that's not possible, the file is broken and should be skipped.
        try:
            mimetype = pywikibot.FilePage(page).latest_file_info.mime
        except pywikibot.PageRelatedError:
            skipped += page.title() + '/n'
            print('Skipping', page)
        else:
            # The categories are a bit messy, so make sure the image isn't
            # already an SVG.
            if mimetype != 'image/svg+xml':
                try:
                    # Grab the global usage of the file, then count the items
                    # and save them in the dictionary.
                    usage = pywikibot.FilePage.globalusage(page)
                    l = len(list(usage))
                    usageCounts[page] = l
                except (pywikibot.NoUsername, pywikibot.PageRelatedError):
                    # Pywikibot complains if the bot doesn't have an account
                    # on a wiki where a file is used. If that happens,
                    # skip the file.
                    skipped += page.title() + '/n'
                    print('Skipping', page)

    # Sort from greatest to least
    usageCountsSorted = sorted(usageCounts, key=usageCounts.__getitem__,
                               reverse=True)

    # Count the global usage for the top 200 files
    i = 0
    j = 200
    totalScanned = len(list(usageCounts))
    sortedPages = ''
    for page in usageCountsSorted:
        if i < j:
            i += 1
            title = page.title()
            count = usageCounts[page]
            sortedPages += '{title}|{i}. Used {count} times.\n'.format(
                title=title, i=i, count=count)
    print('Scanning finished')
    return sortedPages,totalScanned,skipped

def constructGallery(cat, totalScanned, sortedPages, skipped, version, depth):
    
    """Take the output from getUsage() and turn it into a wikitext gallery"""
    
    date = datetime.date.today()
    cats = "'''[[:{maincat}]]''' ({num} files) \n".format(maincat=cat.title(),
    num=cat.categoryinfo['files'])
    pageCats = ('{maincat}\n'
                '[[Category:Images that should use vector graphics]]').format(
                    maincat=cat.aslink())

    # Figure out which subcategories were scanned and turn those into a list
    if depth > 0:
        for subcat in cat.subcategories(recurse=depth - 1):
            cats +=  "* [[:{subcat}]] ({num} files) \n".format(
                subcat=subcat.title(), num=subcat.categoryinfo['files'])

    # If any files were skipped, write an explanatory message and the files.
    if skipped != '':
        skippedFiles = ('The following files were skipped due to errors '
                        'during the generation of this report:/n{skipped}')\
                        .format(skipped=skipped)
    else:
        skippedFiles = ''

    # Now we construct the gallery itself. Everything is formatted by now,
    # it just needs to be slotted into the right spot.
    gallery = """\
Last update: {{{{isodate|1={date}}}}}.

This report includes the following categories while counting only the usage \
of each file in the main namespace.
{cats}

Total number of scanned files: {totalScanned}
<gallery showfilename=yes>
{sortedPages}
</gallery>

This report was generated by AntiCompositeBot {version}. {skippedFiles}

{pageCats}""".format(date=date, cats=cats, totalScanned=totalScanned,
                    sortedPages=sortedPages, skippedFiles=skippedFiles,
                    pageCats=pageCats, version=version)
    return gallery

def savePage(target, gallery):
    """Saves the page to Commons, making sure to leave text above the line"""
    site = pywikibot.Site('commons', 'commons')
    old_wikitext = target.text
    regex = re.compile(
        '(?<=<!-- Only text ABOVE this line '
        'will be preserved on updates -->\n).*', re.M | re.S)
    new_wikitext = re.sub(regex, gallery, old_wikitext)
    print(new_wikitext)
    return
#     target.save(summary='Updating gallery (Bot) ({version})'.format(
        # version=version), botflag=False) 

# This dict contains the pairings between {{Convert to SVG}} values,
# their categories, and the report galleries. It also defines how far into the
# subcategory tree the script will scan. It will eventually live on-wiki,
# but it's staying here for now. I probably could do these pairings
# programatically, but I didn't.
reports = {
        'diagram': {'gallery': 'Top 200 diagram images that should use vector graphics', 'category':'Category:Diagram images that should use vector graphics', 'depth':1},
        'graph': {'gallery': 'Top 200 graph images that should use vector graphics', 'category': 'Category:Graph images that should use vector graphics', 'depth':1},
        'math': {'gallery': 'Top 200 math images that should use vector graphics', 'category': 'Category:Math images that should use vector graphics', 'depth':1},
        'text': {'gallery': 'Top 200 text images that should use vector graphics', 'category': 'Category:Text images that should use vector graphics', 'depth':2},
        'sport': {'gallery': 'Top 200 sport images that should use vector graphics', 'category': 'Category:Sport images that should use vector graphics', 'depth':2},
        'military_insignia': {'gallery': 'Top 200 military insignia images that should use vector graphics', 'category': 'Category:Military insignia images that should use vector graphics', 'depth':0},
        'biology': {'gallery': 'Top 200 biology images that should use vector graphics', 'category': 'Category:Biology images that should use vector graphics', 'depth':1},
        'ribbon': {'gallery': 'Top 200 ribbon images that should use vector graphics', 'category': 'Category:Ribbon images that should use vector graphics', 'depth':1},
        'technology': {'gallery': 'Top 200 technology images that should use vector graphics', 'category': 'Category:Technology images that should use vector graphics', 'depth':1},
        'transport_map': {'gallery': 'Top 200 transport map images that should use vector graphics', 'category': 'Category:Transport map images that should use vector graphics', 'depth':1},
        'chemical': {'gallery': 'Top 200 chemical images that should use vector graphics', 'category': 'Category:Chemical images that should use vector graphics', 'depth':0},
        'physics': {'gallery': 'Top 200 physics images that should use vector graphics', 'category': 'Category:Physics images that should use vector graphics', 'depth':2},
        'chemistry': {'gallery': 'Top 200 chemistry images that should use vector graphics', 'category': 'Category:Chemistry images that should use vector graphics', 'depth':0},
        'sign': {'gallery': 'Top 200 road sign images that should use vector graphics', 'category': 'Category:Road sign images that should use vector graphics', 'depth':0},
        'jpg': {'gallery': 'Top 200 JPG images that should use vector graphics', 'category': 'Category:JPG images that should use vector graphics', 'depth':1},
        'coat_of_arms': {'gallery': 'Top 200 coat of arms images that should use vector graphics', 'category': 'Category:Coat of arms images that should use vector graphics', 'depth':1},
        'locator_map': {'gallery': 'Top 200 locator map images that should use vector graphics', 'category': 'Category:Locator map images that should use vector graphics', 'depth':0},
        'logo': {'gallery': 'Top 200 logo images that should use vector graphics', 'category': 'Logo images that should use vector graphics', 'depth':1},
        'map': {'gallery': 'Top 200 map images that should use vector graphics', 'category': 'Category:Map images that should use vector graphics', 'depth':2},
        'flag': {'gallery': 'Top 200 flag images that should use vector graphics', 'category':'Category:Flag images that should use vector graphics', 'depth':1},
        'symbol of municipalities in Japan': {'gallery': 'Top 200 symbol of municipalities in Japan images that should use vector graphics', 'category': 'Symbol of municipalities in Japan images that should use vector graphics', 'depth':1}
}

# Handle command line arguments. Requires the key for the reports dict
# Optional argument --total limits the files scanned
# and --simulate prevents saving.
parser = argparse.ArgumentParser(
    description='Generate global usage reports for vectorization categories.')
parser.add_argument('key')
parser.add_argument('--total', help="maximum number of files to scan",
                    type=int, default=None)
parser.add_argument('--simulate',
                    help="prints output to SDOUT instead of saving it",
                    action="store_true")
args = parser.parse_args()

# Alright, into the main body of the script. Set up pywikibot to operate 
# off of Commons using the category and target gallery from the input key.
site = pywikibot.Site('commons', 'commons')
cat = pywikibot.Category(site, reports[args.key]['category'])
target = pywikibot.Page(site, reports[args.key]['gallery'])
depth = reports[args.key]['depth']
total = args.total

# Log the version and the start time
print('AntiCompositeBot {version} started at {starttime}'.format(
    version=version, starttime=datetime.datetime.now().isoformat()))

# Run getUsage() with the cat based on the input. Returns the files with 
# their usage, the total number scanned, and any that were skipped.
sortedPages,totalScanned,skipped = getUsage(cat, depth, total)

# Use all the information gathered or supplied to construct the report gallery.
gallery = constructGallery(cat, totalScanned, sortedPages, skipped,
                           version, depth)
# Check if we're actually writing to the report gallery. If not, just print
# the gallery wikitext to SDOUT. If we are, send it to savePage().
if args.simulate:
    print(gallery)
else:
    savePage(target, gallery)

#We're done here.
print('Finished')
